<!DOCTYPE html> <html lang="en"> <head> <meta name="google-site-verification" content="hDA3AMf31FYDR4O0cr5UGJ7SXCLOmoDXKnQUt4x-X_g"/> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Towards Conditionality in Probabilistic Diffusion Models | Simone Antonelli</title> <meta name="author" content="Simone Antonelli"/> <meta name="description" content="Adaptation of GANs techniques for class-conditionality to probabilistic diffusion models."/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website, simone, antonelli, simone antonelli, simone antonelli sapienza, simone antonelli uniroma1, simone antonelli cispa, cispa helmholtz, sapienza university of rome, computer science, artificial intelligence, ai, machine learning, deep learning, graph neural network, graph representation learning, few shot learning, graphs, networks"/> <meta property="og:site_name" content="Simone Antonelli"/> <meta property="og:type" content="website"/> <meta property="og:title" content="Simone Antonelli | Towards Conditionality in Probabilistic Diffusion Models"/> <meta property="og:url" content="https://siantonelli.github.io/projects/ProbDiffModels/"/> <meta property="og:description" content="Adaptation of GANs techniques for class-conditionality to probabilistic diffusion models."/> <meta property="og:image" content="favicon.svg"/> <meta property="og:locale" content="en"/> <meta name="twitter:card" content="summary"/> <meta name="twitter:title" content="Towards Conditionality in Probabilistic Diffusion Models"/> <meta name="twitter:description" content="Adaptation of GANs techniques for class-conditionality to probabilistic diffusion models."/> <meta name="twitter:image" content="favicon.svg"/> <meta name="twitter:site" content="@sntonelli"/> <meta name="twitter:creator" content="@sntonelli"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/favicon.svg"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://siantonelli.github.io/projects/ProbDiffModels/"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Simone </span>Antonelli</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Towards Conditionality in Probabilistic Diffusion Models</h1> <p class="post-description">Adaptation of GANs techniques for class-conditionality to probabilistic diffusion models.</p> </header> <article> <h1 id="introduction">Introduction</h1> <p>Image synthesis is a core task in machine learning, and until now, Generative Adversarial Networks have been the state-of-the-art for it; but recently, <a href="http://arxiv.org/abs/2006.11239" target="_blank" rel="noopener noreferrer">J. Ho et al. 2020</a> shows that similar performance can be obtained with a different model, which instead leverages probabilistic diffusion, named in fact <em>Denoising Diffusion Probabilistic Model</em>.</p> <p>One major application of generative models is dataset augmentation, but in order to generate new images belonging to a certain class, one would need to have a conditional model. The goal of this project is to integrate class-conditionality in probabilistic diffusion models.</p> <h1 id="method">Method</h1> <p>A <em>diffusion probabilistic model</em> is a parameterized Markov chain.</p> <figure> <p><img src="/assets/img/markov-diffusion.png" alt="Diffusion Probabilistic Model" title="Diffusion probabilistic model as a markov chain"></p> </figure> <p>The training phase consists of two phases:</p> <ul> <li>a forward pass, also called the <em>diffusion process</em>, Gaussian noise is added to the image according to a fixed schedule so each transition in the Markov chain \(\begin{align*} q(\mathbf{x}_{t}| \mathbf{x}_{t-1}) \end{align*}\) represents the addition of Gaussian noise, and</li> <li>a reverse pass, where the transitions of a reverse Markov chain are learned in order to reconstruct the destroyed signal</li> </ul> <p>The parameters are learned by optimizing the variational bound on negative log-likelihood:</p> \[\begin{align*} \mathbb{E}\left[ - \log p_{\theta}(\mathbf{x}_0) \right] &amp;\leq \mathbb{E}_q \left[ - \log \frac{p_\theta (\mathbf{x}_0, \dots, \mathbf{x}_T)}{q(\mathbf{x}_1, \dots, \mathbf{x}_T|\mathbf{x}_0)}\right] \\ &amp;= \mathbb{E}_q\left[ - \log \ p(\mathbf{x}_T) - \sum_{t \geq 1} \log \frac{p_\theta (\mathbf{x}_{t-1}|\mathbf{x}_t)}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right] \end{align*}\] <p>Since the parameters for the forward pass are fixed, the only parameters to be learned are the ones of the denoiser, which is based on the popular <em>U-net</em> architecture (<a href="http://arxiv.org/abs/1505.04597" target="_blank" rel="noopener noreferrer">O. Ronneberger et al. 2015</a>).</p> <p align="center"><img src="/assets/img/U-net.png" alt="U-Net" title="U-Net architecture for the denoiser"></p> <p>The implementation is based on the GitHub repository <a href="https://github.com/lucidrains/denoising-diffusion-pytorch" target="_blank" rel="noopener noreferrer">denoising-diffusion-pytorch</a>, which provides a working <em>PyTorch</em> baseline.</p> <h4 id="conditional-batch-norm">Conditional Batch Norm</h4> <p><em>Conditional Batch Norm</em> builds upon <em>Batch Normalization</em>, in which each batch is normalized as follows to reduce the internal co-variate shift:</p> \[\begin{equation*} \text{BN}_{\gamma, \beta}(x_i) = \gamma_i \frac{x_i - \mathbb{E}(x_i)}{\sqrt{var(x_i)}} + \beta_i \end{equation*}\] <p>In <em>Conditional Batch Norm</em>, we want to predict \(\gamma\) and \(\beta\) from an embedding of the class so that the class may manipulate entire feature maps by scaling them up or down, negating them, or shutting them off completely.</p> <p>The integration of <em>Conditional Batch Norm</em> in the architecture is done by replacing the <em>Batch Normalization</em> layers inside the denoiser architecture with conditional ones.</p> <h4 id="auxiliary-classifier">Auxiliary classifier</h4> <p>Following the idea of <a href="https://arxiv.org/abs/1610.09585" target="_blank" rel="noopener noreferrer">A. Odena et al. 2016</a>, an extra classifier is added to the denoiser architecture.</p> <p>With the aim of providing the class information to the latter, the label is embedded, properly reshaped, and concatenated to the channel dimension of the image.</p> <p>The overall loss is then obtained as a weighted sum of the reconstruction loss and the classifier loss, where the weight is a hyper-parameter. The loss should this way be enriched with class information that should backpropagate to the parameters that are involved in the generation.</p> <h1 id="dataset">Dataset</h1> <p>Our original goal at the start of the project was to apply the model to the <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_IP102_A_Large-Scale_Benchmark_Dataset_for_Insect_Pest_Recognition_CVPR_2019_paper.pdf" target="_blank" rel="noopener noreferrer">insect-pest dataset</a> to create new artificial samples for classification. Nevertheless, the dataset was not large enough to train different unconditional models for each of the classes, and so we instead decided to integrate class conditionality into the model itself. But most of the classes of the dataset had few samples and low variance between them, and it is often hard even for humans to understand what’s in the image.</p> <p>Therefore, to have a simple benchmark to test our proposed conditional methods, we created an ad-hoc dataset of only two classes with a maximum difference, namely a subset of the <a href="http://vision.stanford.edu/aditya86/ImageNetDogs/" target="_blank" rel="noopener noreferrer">Stanford dogs</a> and a subset of the <a href="http://ai.stanford.edu/~jkrause/cars/car_dataset.html" target="_blank" rel="noopener noreferrer">Stanford cars</a> datasets</p> <h1 id="results">Results</h1> <p>The unconditional model yielded the following results on the insect-pest dataset</p> <figure> <p><img src="/assets/img/unconditional-insects-64.png" alt="Unconditional results 64" title="Results of the unconditional model fed with image at resolution of 64"> <img src="/assets/img/unconditional-insects-128.png" alt="Unconditional results 128" title="Results of the unconditional model fed with image at resolution of 128"></p> <figcaption>(Right) ‘Resolution 64 vs (Left) Resolution 128</figcaption> </figure> <p>We can see that by feeding the model with higher resolution images, the results are way more realistic, as the model is able to exploit the larger amount of information given.</p> <p>Regarding the conditional model, the two proposed methods yielded totally different results.</p> <hr> <p>The next are the results of the <em>Conditional Batch Norm</em> model</p> <figure> <p><img src="/assets/img/cbn-generated-dogs.png" alt="CBN dogs results" title="Results of the conditional batch norm model on dogs class images"> <img src="/assets/img/cbn-generated-cars.png" alt="CBN cars results" title="Results of the conditional batch norm model on cars class images"></p> <figcaption>(Right) ‘Dog’ class vs (Left) ‘Car’ class</figcaption> </figure> <p>Despite the fact that the results are somehow funny, we can easily agree with the class generated by the model.</p> <p>As the reconstruction error is small, the problem seems to be related to the sampling procedure, and indeed it might be the case that the class information is not accounted for correctly during sampling.</p> <p>To check whether there is a class-related distinction between the generated images, the images are plotted as <em>t-SNE</em></p> <p align="center"><img src="/assets/img/CBN-t-sne-images.png" alt="CBN t-SNE plot" title="t-SNE plot of the conditional batch norm's results"></p> <p>The points seem to be fairly separable, indicating that the class is indeed infused in the generated images.</p> <hr> <p>Instead, the <em>Auxiliary Classifier</em> model results in the converse, yielding more realistic images that do not seem to be much influenced by the class, as we can see from these results</p> <figure> <p><img src="/assets/img/ac-generated-dogs.png" alt="AC dogs results" title="Results of the auxiliary classifier model on dogs class images"> <img src="/assets/img/ac-generated-cars.png" alt="AC cars results" title="Results of the auxiliary classifier model on cars class images"></p> <figcaption>(Right) ‘Dog’ class vs (Left) ‘Car’ class</figcaption> </figure> <p>To avoid co-adaptation between the classifier and the generator during training, we pre-trained the classifier on the dataset of real images and then kept its parameters fixed during the training of the rest of the model.</p> <p>Also, higher-resolution images are fed to the model but with no significant improvement. The generated images, in fact, do not resemble their class, but the classification loss is still able to become really low</p> <p align="center"><img src="/assets/img/ac-generated-128.png" alt="AC high res results" title="Results of the auxiliary classifier model on high resolution images"></p> <p>Visually inspecting the images turns out that artifacts were present in every image, probably resulting from the generator <em>tricking</em> the classifier, emphasizing features that resulted in high confidence guesses in the latter.</p> <p>As before, <em>t-SNE</em> is employed to check whether there is a class-related distinction between the images</p> <p align="center"><img src="/assets/img/AC-t-sne-images.png" alt="AC t-SNE plot" title="t-SNE plot of the auxiliary classifier's results"></p> <p>As can be seen, this time, the points are all mixed up, indicating that the model fails in conditioning the generation on the class.</p> <h1 id="conclusions">Conclusions</h1> <p>The proposed methods do not yield acceptable results, indicating that it is not enough to adapt GANs techniques for class-conditionality to probabilistic diffusion models, while this is also not straightforward to do. This also emphasizes that, while seemingly close to GANs, this family of models requires ad-hoc research, as they are based on different theoretical aspects.</p> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2023 Simone Antonelli. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Last updated: February 22, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-XCK458LS4R"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-XCK458LS4R");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>