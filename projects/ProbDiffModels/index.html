<!DOCTYPE html>
<html lang="en">

<!-- Head -->

<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <script id="Cookiebot" src="https://consent.cookiebot.com/uc.js" data-cbid="db78cf14-979d-40d8-a2ac-c8f9eaa1f298" data-blockingmode="auto" type="text/javascript"></script><!-- Metadata, OpenGraph and Schema.org -->

<!-- Website verification -->
<meta name="google-site-verification" content="hDA3AMf31FYDR4O0cr5UGJ7SXCLOmoDXKnQUt4x-X_g">
<!-- Avoid warning on Google Chrome
        Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'interest-cohort'.
        see https://stackoverflow.com/a/75119417
    -->
<meta http-equiv="Permissions-Policy" content="interest-cohort=()">

<!-- Standard metadata -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Towards Conditionality in Probabilistic Diffusion Models | Simone  Antonelli</title>
<meta name="author" content="Simone  Antonelli">
<meta name="description" content="Adaptation of GANs techniques for class-conditionality to probabilistic diffusion models.">
<meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website, simone, antonelli, simone antonelli, simone antonelli sapienza, simone antonelli uniroma1, simone antonelli cispa, cispa helmholtz, sapienza university of rome, computer science, artificial intelligence, ai, machine learning, deep learning, graph neural network, graph representation learning, few shot learning, graphs, networks">

<!-- OpenGraph -->
<meta property="og:site_name" content="Simone  Antonelli">
<meta property="og:type" content="website">
<meta property="og:title" content="Simone  Antonelli | Towards Conditionality in Probabilistic Diffusion Models">
<meta property="og:url" content="https://siantonelli.github.io/projects/ProbDiffModels/">
<meta property="og:description" content="Adaptation of GANs techniques for class-conditionality to probabilistic diffusion models.">
<meta property="og:image" content="favicon.svg">
<meta property="og:locale" content="en">

<!-- Twitter card -->
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Towards Conditionality in Probabilistic Diffusion Models">
<meta name="twitter:description" content="Adaptation of GANs techniques for class-conditionality to probabilistic diffusion models.">
<meta name="twitter:image" content="favicon.svg">
<meta name="twitter:site" content="@sntonelli">
<meta name="twitter:creator" content="@sntonelli">

<!-- Bootstrap & MDB -->
<link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

<!-- Bootstrap Table -->
<link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.css">

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">



<!-- Styles -->

  <link rel="shortcut icon" href="/assets/img/favicon.svg">
  
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="https://siantonelli.github.io/projects/ProbDiffModels/">

  <!-- Dark Mode -->
  
</head>

<!-- Body -->

<body class="fixed-top-nav sticky-bottom-footer">

  <!-- Header --><header>

  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">SimoneÂ </span>Antonelli</a>
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">About</a>
          </li>
          

          <!-- Other pages -->
          <li class="nav-item ">
            <a class="nav-link" href="/publications/">Publications</a>
          </li>
          <li class="nav-item ">
            <a class="nav-link" href="/projects/">Projects</a>
          </li>
          <li class="nav-item ">
            <a class="nav-link" href="/repositories/">Repositories</a>
          </li>
          <li class="nav-item ">
            <a class="nav-link" href="/cv/">CV</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>
  
  <!-- Scrolling Progress Bar -->
  <progress id="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress>
</header>

  <!-- Content -->
  <div class="container mt-5">
    
    <!-- page.html -->
<div class="post">

  <header class="post-header">
    <h1 class="post-title">Towards Conditionality in Probabilistic Diffusion Models</h1>
    <p class="post-description">Adaptation of GANs techniques for class-conditionality to probabilistic diffusion models.</p>
  </header>

  <article>
    <h1 id="introduction">Introduction</h1>

<p>Image synthesis is a core task in machine learning, and until now, Generative Adversarial Networks have been the state-of-the-art for it; but recently, <a href="http://arxiv.org/abs/2006.11239" rel="external nofollow noopener" target="_blank">J. Ho et al. 2020</a> shows that similar performance can be obtained with a different model, which instead leverages probabilistic diffusion, named in fact <em>Denoising Diffusion Probabilistic Model</em>.</p>

<p>One major application of generative models is dataset augmentation, but in order to generate new images belonging to a certain class, one would need to have a conditional model. The goal of this project is to integrate class-conditionality in probabilistic diffusion models.</p>

<h1 id="method">Method</h1>

<p>A <em>diffusion probabilistic model</em> is a parameterized Markov chain.</p>

<figure>
<p><img src="/assets/img/markov-diffusion.png" alt="Diffusion Probabilistic Model" title="Diffusion probabilistic model as a markov chain"></p>
</figure>

<p>The training phase consists of two phases:</p>
<ul>
  <li>a forward pass, also called the <em>diffusion process</em>, Gaussian noise is added to the image according to a fixed schedule so each transition in the Markov chain
\(\begin{align*}
  q(\mathbf{x}_{t}| \mathbf{x}_{t-1})
\end{align*}\) represents the addition of Gaussian noise, and</li>
  <li>a reverse pass, where the transitions of a reverse Markov chain are learned in order to reconstruct the destroyed signal</li>
</ul>

<p>The parameters are learned by optimizing the variational bound on negative log-likelihood:</p>

\[\begin{align*}
	\mathbb{E}\left[ - \log p_{\theta}(\mathbf{x}_0) \right] &amp;\leq \mathbb{E}_q \left[ - \log \frac{p_\theta (\mathbf{x}_0, \dots, \mathbf{x}_T)}{q(\mathbf{x}_1, \dots, \mathbf{x}_T|\mathbf{x}_0)}\right] \\
	&amp;= \mathbb{E}_q\left[ - \log \ p(\mathbf{x}_T) - \sum_{t \geq 1} \log \frac{p_\theta (\mathbf{x}_{t-1}|\mathbf{x}_t)}{q(\mathbf{x}_t | \mathbf{x}_{t-1})} \right]
\end{align*}\]

<p>Since the parameters for the forward pass are fixed, the only parameters to be learned are the ones of the denoiser, which is based on the popular <em>U-net</em> architecture (<a href="http://arxiv.org/abs/1505.04597" rel="external nofollow noopener" target="_blank">O. Ronneberger et al. 2015</a>).</p>

<p align="center"><img src="/assets/img/U-net.png" alt="U-Net" title="U-Net architecture for the denoiser"></p>

<p>The implementation is based on the GitHub repository <a href="https://github.com/lucidrains/denoising-diffusion-pytorch" rel="external nofollow noopener" target="_blank">denoising-diffusion-pytorch</a>, which provides a working <em>PyTorch</em> baseline.</p>

<h4 id="conditional-batch-norm">Conditional Batch Norm</h4>

<p><em>Conditional Batch Norm</em> builds upon <em>Batch Normalization</em>, in which each batch is normalized as follows to reduce the internal co-variate shift:</p>

\[\begin{equation*}
	\text{BN}_{\gamma, \beta}(x_i) = \gamma_i \frac{x_i - \mathbb{E}(x_i)}{\sqrt{var(x_i)}} + \beta_i
\end{equation*}\]

<p>In <em>Conditional Batch Norm</em>, we want to predict \(\gamma\) and \(\beta\) from an embedding of the class so that the class may manipulate entire feature maps by scaling them up or down, negating them, or shutting them off completely.</p>

<p>The integration of <em>Conditional Batch Norm</em> in the architecture is done by replacing the <em>Batch Normalization</em> layers inside the denoiser architecture with conditional ones.</p>

<h4 id="auxiliary-classifier">Auxiliary classifier</h4>

<p>Following the idea of <a href="https://arxiv.org/abs/1610.09585" rel="external nofollow noopener" target="_blank">A. Odena et al. 2016</a>, an extra classifier is added to the denoiser architecture.</p>

<p>With the aim of providing the class information to the latter, the label is embedded, properly reshaped, and concatenated to the channel dimension of the image.</p>

<p>The overall loss is then obtained as a weighted sum of the reconstruction loss and the classifier loss, where the weight is a hyper-parameter. The loss should this way be enriched with class information that should backpropagate to the parameters that are involved in the generation.</p>

<h1 id="dataset">Dataset</h1>

<p>Our original goal at the start of the project was to apply the model to the <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_IP102_A_Large-Scale_Benchmark_Dataset_for_Insect_Pest_Recognition_CVPR_2019_paper.pdf" rel="external nofollow noopener" target="_blank">insect-pest dataset</a> to create new artificial samples for classification. 
Nevertheless, the dataset was not large enough to train different unconditional models for each of the classes, and so we instead decided to integrate class conditionality into the model itself.
But most of the classes of the dataset had few samples and low variance between them, and it is often hard even for humans to understand whatâs in the image.</p>

<p>Therefore, to have a simple benchmark to test our proposed conditional methods, we created an ad-hoc dataset of only two classes with a maximum difference, namely a subset of the <a href="http://vision.stanford.edu/aditya86/ImageNetDogs/" rel="external nofollow noopener" target="_blank">Stanford dogs</a> and a subset of the <a href="http://ai.stanford.edu/~jkrause/cars/car_dataset.html" rel="external nofollow noopener" target="_blank">Stanford cars</a> datasets</p>

<h1 id="results">Results</h1>

<p>The unconditional model yielded the following results on the insect-pest dataset</p>

<figure>
<p><img src="/assets/img/unconditional-insects-64.png" alt="Unconditional results 64" title="Results of the unconditional model fed with image at resolution of 64">
<img src="/assets/img/unconditional-insects-128.png" alt="Unconditional results 128" title="Results of the unconditional model fed with image at resolution of 128"></p>
  <figcaption>(Right) âResolution 64 vs (Left) Resolution 128</figcaption>
</figure>

<p>We can see that by feeding the model with higher resolution images, the results are way more realistic, as the model is able to exploit the larger amount of information given.</p>

<p>Regarding the conditional model, the two proposed methods yielded totally different results.</p>

<hr>

<p>The next are the results of the <em>Conditional Batch Norm</em> model</p>

<figure>
<p><img src="/assets/img/cbn-generated-dogs.png" alt="CBN dogs results" title="Results of the conditional batch norm model on dogs class images">
<img src="/assets/img/cbn-generated-cars.png" alt="CBN cars results" title="Results of the conditional batch norm model on cars class images"></p>
  <figcaption>(Right) âDogâ class vs (Left) âCarâ class</figcaption>
</figure>

<p>Despite the fact that the results are somehow funny, we can easily agree with the class generated by the model.</p>

<p>As the reconstruction error is small, the problem seems to be related to the sampling procedure, and indeed it might be the case that the class information is not accounted for correctly during sampling.</p>

<p>To check whether there is a class-related distinction between the generated images, the images are plotted as <em>t-SNE</em></p>

<p align="center"><img src="/assets/img/CBN-t-sne-images.png" alt="CBN t-SNE plot" title="t-SNE plot of the conditional batch norm's results"></p>

<p>The points seem to be fairly separable, indicating that the class is indeed infused in the generated images.</p>

<hr>

<p>Instead, the <em>Auxiliary Classifier</em> model results in the converse, yielding more realistic images that do not seem to be much influenced by the class, as we can see from these results</p>

<figure>
<p><img src="/assets/img/ac-generated-dogs.png" alt="AC dogs results" title="Results of the auxiliary classifier model on dogs class images">
<img src="/assets/img/ac-generated-cars.png" alt="AC cars results" title="Results of the auxiliary classifier model on cars class images"></p>
  <figcaption>(Right) âDogâ class vs (Left) âCarâ class</figcaption>
</figure>

<p>To avoid co-adaptation between the classifier and the generator during training, we pre-trained the classifier on the dataset of real images and then kept its parameters fixed during the training of the rest of the model.</p>

<p>Also, higher-resolution images are fed to the model but with no significant improvement. The generated images, in fact, do not resemble their class, but the classification loss is still able to become really low</p>

<p align="center"><img src="/assets/img/ac-generated-128.png" alt="AC high res results" title="Results of the auxiliary classifier model on high resolution images"></p>

<p>Visually inspecting the images turns out that artifacts were present in every image, probably resulting from the generator <em>tricking</em> the classifier, emphasizing features that resulted in high confidence guesses in the latter.</p>

<p>As before, <em>t-SNE</em> is employed to check whether there is a class-related distinction between the images</p>

<p align="center"><img src="/assets/img/AC-t-sne-images.png" alt="AC t-SNE plot" title="t-SNE plot of the auxiliary classifier's results"></p>

<p>As can be seen, this time, the points are all mixed up, indicating that the model fails in conditioning the generation on the class.</p>

<h1 id="conclusions">Conclusions</h1>

<p>The proposed methods do not yield acceptable results, indicating that it is not enough to adapt GANs techniques for class-conditionality to probabilistic diffusion models, while this is also not straightforward to do.
This also emphasizes that, while seemingly close to GANs, this family of models requires ad-hoc research, as they are based on different theoretical aspects.</p>

  </article>

</div>
    
  </div>

  <!-- Footer --><footer class="sticky-bottom mt-5">
  <div class="container">
    Â© Copyright 2023 Simone  Antonelli. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme.
Last updated: June 21, 2023.
  </div>
</footer>

  <!-- JavaScripts -->
  <!-- jQuery -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <!-- Bootsrap & MDB scripts -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>
  <!-- Masonry & imagesLoaded -->
<script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/masonry.js" type="text/javascript"></script>
  
<!-- Medium Zoom JS -->
<script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
<script defer src="/assets/js/zoom.js"></script>

<!-- Bootstrap Table -->
<script defer src="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/no_defer.js"></script>
<script defer src="/assets/js/common.js"></script>
<script defer src="/assets/js/copy_code.js" type="text/javascript"></script>
  
<script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
<script async src="https://badge.dimensions.ai/badge.js"></script>
  <!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-XCK458LS4R"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { window.dataLayer.push(arguments); }
  gtag('js', new Date());
  gtag('config', 'G-XCK458LS4R');
</script>
  

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function () {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>
</body>

</html>
